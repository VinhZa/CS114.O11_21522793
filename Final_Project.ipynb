{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "178IcsrYWPnW"
      },
      "outputs": [],
      "source": [
        "#Task 1: Khai báo môi trường và các thư viện cần thiết; Cho biết các thư viện đó ứng dụng vào việc gì\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt     #Thư viện này để vẽ đồ thị\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping     #thư viện này để gọi hàm call back trong quá trình training\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator       #thư viện này để gọi hàm tăng cường dữ liệu\n",
        "from tensorflow.keras.preprocessing import image                          #dùng load image\n",
        "from tensorflow.keras.models import Sequential                            #dùng xây dựng CNN tuần tự\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,\n",
        "BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D                #nhập các lớp cho CNN\n",
        "from tensorflow.keras.optimizers import Adam                              #import trình tối ưu hóa\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP74jiFyWeyN"
      },
      "outputs": [],
      "source": [
        "#Task 2: định dạng hình ảnh, nạp dữ liệu train\n",
        "im_shape = (250,250)    #xác định kích thước hình ảnh\n",
        "seed = 10               #số trạng thái ngẫu nhiên sẽ được giữ nguyên qua các lần epoch\n",
        "BATCH_SIZE = 20         #số ảnh được thực hiện trong 1 bước của epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAzcgkcAYxHG"
      },
      "outputs": [],
      "source": [
        "rm -rf `find -type d -name .ipynb_checkpoints`    #Xóa class inynbcheckpoint có sẵn trong jupiter notebook dùng để ghi nhớ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK_7IXtTWkjx"
      },
      "outputs": [],
      "source": [
        "#Tạo tập generator, dùng để huấn luyện dữ liệu\n",
        "data_generator = ImageDataGenerator(\n",
        "        validation_split=0.2,         # Tỉ lệ phần trăm dữ liệu được sử dụng cho validation set (tách từ dữ liệu huấn luyện)\n",
        "        rotation_range=20,            # Góc quay ảnh (degrees)\n",
        "        width_shift_range=0.2,        # Phạm vi dịch chuyển theo chiều ngang (tỷ lệ của bức ảnh)\n",
        "        height_shift_range=0.2,       # Phạm vi dịch chuyển theo chiều dọc (tỷ lệ của bức ảnh)\n",
        "        rescale=1./255,               # Tỉ lệ giảm độ sáng theo pixel\n",
        "        shear_range=0.2,              # Góc cắt (shear) ảnh\n",
        "        zoom_range=0.2,               # Tỉ lệ thu phóng ngẫu nhiên\n",
        "        horizontal_flip=True,         # Lật ngang ảnh theo chiều ngang\n",
        "        brightness_range=[0.8, 1.2],  # Phạm vi độ sáng của ảnh\n",
        "        channel_shift_range=0.2,      # Phạm vi dịch chuyển kênh màu (RGB) theo chiều ngang\n",
        "        vertical_flip=True,           # Lật dọc ảnh\n",
        "        fill_mode='nearest')          # trong lúc biến đổi hình ảnh, sẽ xuất hiện các pixel trống và chúng được điền theo pixel gần nhất\n",
        "\n",
        "val_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)   #tạo tập valid_gen bằng cách lấy 20% số ảnh của tập train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BeIU-NCWvbL"
      },
      "outputs": [],
      "source": [
        "  #Task này có thay đổi ở tập test, sử dụng tập validation để tạo bảng confusion matrix\n",
        "  train_generator = data_generator.flow_from_directory('/content/train', target_size=im_shape, shuffle=True, seed=seed,class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
        "  #tập train_generator có tác dụng tạo ra dữ liệu hình ảnh cho các batch, ở đây sử dụng size(250,250), xóa trộn ảnh để các batch luôn được ngẫu nhiên, class_mode categorical có sẽ biểu diễn label dưới dạng nhị phân theo số lớp, ví dụ như này: \"Cat\": [1, 0, 0], với mục đích (subset) là training\n",
        "  validation_generator = val_data_generator.flow_from_directory('/content/train', target_size=im_shape, shuffle=False, seed=seed,class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\") #giống tập train\n",
        "\n",
        "  nb_train_samples = train_generator.samples        # lưu ảnh từ tập vào biến để sử dụng\n",
        "  nb_validation_samples = validation_generator.samples\n",
        "\n",
        "  classes = list(train_generator.class_indices.keys())   # kiểm tra và in ra tên của các lớp trong tập huấn luyện\n",
        "  print('Classes: '+str(classes))\n",
        "  num_classes  = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDqpsAHPTZEf"
      },
      "outputs": [],
      "source": [
        "#kiểm tra các ảnh được tạo ra và biến đổi từ tập generator\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    batch = train_generator.next()[0] * 255\n",
        "    image = batch[0].astype('uint8')\n",
        "    # Định dạng khác nhau\n",
        "    if i % 2 == 0:\n",
        "        plt.imshow(image, cmap='viridis')  # Định dạng cmap\n",
        "    else:\n",
        "        plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Image {i+1}')\n",
        "    # Ẩn các trục\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL-M6cNNW0w_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()                                          #tạo mô hình tuần tự, dữ liệu lớp này sẽ chuyển tới lớp tiếp theo\n",
        "model.add(Conv2D(20, kernel_size=(3, 3),                      #tạo lớp tích chập với 20 nơ ron, kernel là 1 ma trận dùng để học các đặc trưng không gian như cạnh góc, pattern cục bộ của dữ liệu, act = relu để học nhiều đặc trưng phi tuyến tính(là học mấy cái biểu diễn phức tạp), kích thước hình ảnh 250x250 và nhận kênh 3 màu RGB\n",
        "                 activation='relu',\n",
        "                 input_shape=(250,250,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))                     #giảm độ phức tạp, tham số cần học và kích thước của đầu ra từ lớp conv2d trước đó\n",
        "model.add(Conv2D(40, kernel_size=(3,3), activation='relu'))   #thêm 1 lớp conv2d nữa để mô hình học sâu hơn, ví dụ lớp trc đó học được viền và cạnh góc gì đó thì giờ nó học sâu hơn là texture, pattern hoặc đối tượng cụ thể\n",
        "model.add(Flatten())                                          #chuyển các đầu ra 2d hoặc 3d thành vector 1 chiều có chứa các đặc trưng để đưa vào lớp dense (dense là fully connected nên chỉ có 1 chiều thôi)\n",
        "model.add(Dense(100, activation='relu'))                      #lớp này kết nối các nơ ron từ các lớp trước đó lại với nhau, nghĩa là mỗi nơ ron trong dense sẽ được kết nối 1 trong 100 nơ ron có cùng trọng số trước đó\n",
        "model.add(Dropout(0.2))                                       #cắt bớt đặc trưng, giúp mô hình không quá phụ thuốc vào các đặc trưng mà còn có thể phân loại đa dạng hình ảnh hơn\n",
        "model.add(Dense(num_classes, activation='softmax'))           #lớp kết nối cuối cùng với act = softmax để tạo ra bài toán phân loại, ví dụ trong này 3 lớp thì có 3 xác suất, cái xác suất nào lớn nhất thì chọn làm dự đoán prediction cuối cùng\n",
        "model.summary()                                               #hiện bảng tóm tắt như ở dưới\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',                #khai báo hàm mất mát có sẵn trong thư viện của Keras\n",
        "              optimizer=Adam(),                               #trình tối ưu hóa Adam\n",
        "              metrics=['accuracy'])                           #chọn độ đo cho dự đoán, ở đây là tỉ lệ chính xác (độ đo là các phép tính toán như f1, recall, precision đồ đó)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM-vDTU1W3Wv"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "# Định nghĩa các callbacks\n",
        "checkpoint_callback = ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True, verbose=1)    #lưu trạng thái vào 1 tệp mỗi lần epoch được gọi, trong đó monitor theo dõi metrics val_loss, nếu như val_loss giảm so với lần epoch trước thì lưu, verbose để hiện thông báo là xong rồi thôi\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2, verbose=1)                                #nếu val_loss sau 2 epoch mà không giảm được thì hàm này được gọi để dừng train\n",
        "\n",
        "# Gộp các callbacks vào một list\n",
        "callbacks_list = [checkpoint_callback, early_stopping_callback]                                                   #dùng 2 callback này để tránh overfitting và tiết kiệm thời gian train\n",
        "\n",
        "#Training\n",
        "history = model.fit(                                                                                              #bắt đầu huần luyện\n",
        "        train_generator,\n",
        "        steps_per_epoch=nb_train_samples // BATCH_SIZE,                                                           #số bước trong 1 epoch = số ảnh / số ảnh trong 1 lô (batch)\n",
        "        epochs=epochs,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data=validation_generator,\n",
        "        verbose = 1,\n",
        "        validation_steps=nb_validation_samples // BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CjKUWdQW6jQ"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "#vẽ đồ thị loss theo từng epoch\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs_x = range(1, len(loss_values) + 1)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(epochs_x, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation Loss and Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "#vẽ đồ thị acc theo từng epoch\n",
        "plt.legend()\n",
        "plt.subplot(2,1,2)\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "plt.plot(epochs_x, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTuhDxiaW_bq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToptQcSQXObw"
      },
      "outputs": [],
      "source": [
        "import itertools #\n",
        "\n",
        "#Plot the confusion matrix. Set Normalize = True/False\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkSECj6-P_EZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, data_generator, classes):\n",
        "    # Dự đoán nhãn cho tập dữ liệu\n",
        "    predictions = model.predict_generator(data_generator)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Lấy nhãn thực tế từ tập dữ liệu\n",
        "    true_labels = data_generator.classes\n",
        "\n",
        "    # Tính confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Hiển thị thông tin và vẽ confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Vẽ confusion matrix bằng cách sử dụng hàm plot_confusion_matrix\n",
        "    plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix')\n",
        "\n",
        "    # Classification Report\n",
        "    print('\\nClassification Report:')\n",
        "    print(classification_report(true_labels, predicted_labels, target_names=classes))\n",
        "\n",
        "# Sử dụng hàm evaluate_model\n",
        "evaluate_model(model, validation_generator, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LReyx9oOdPDB"
      },
      "outputs": [],
      "source": [
        "#Vừa xuất file đúng với tên ban đầu, vừa xuất ra màn hình với predicted label và được resize\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Đường dẫn đến thư mục chứa ảnh test\n",
        "test_dir = '/content/test'  # Điều chỉnh đường dẫn tới thư mục chứa ảnh test bên ngoài\n",
        "\n",
        "# Tạo một list chứa đường dẫn đầy đủ đến từng ảnh trong thư mục test\n",
        "test_images = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
        "\n",
        "# Kích thước mới cho việc hiển thị\n",
        "display_size = (250, 250)\n",
        "\n",
        "# Khởi tạo một thư mục để lưu các ảnh dự đoán\n",
        "output_dir = '/content/o5'  # Điều chỉnh đường dẫn đến thư mục output\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Duyệt qua từng ảnh trong tập test\n",
        "for i in range(0, len(test_images), 4):  # Process images in batches of 4\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "\n",
        "    for j, img_path in enumerate(test_images[i:i+4]):\n",
        "        # Đọc và resize ảnh về kích thước phù hợp với mô hình\n",
        "        img = image.load_img(img_path, target_size=display_size)\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array /= 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\n",
        "        # Dự đoán nhãn cho ảnh sử dụng model đã được train và lưu vào model.hd5 và gán thành biến model\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_label = np.argmax(predictions, axis=1)\n",
        "        # Lấy tên nhãn dự đoán từ class_indices\n",
        "        predicted_class = [k for k, v in train_generator.class_indices.items() if v == predicted_label[0]][0]\n",
        "        # Tạo thư mục con cho mỗi nhãn nếu chưa tồn tại\n",
        "        label_dir = os.path.join(output_dir, predicted_class)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        # Copy ảnh vào thư mục của nhãn\n",
        "        shutil.copy(img_path, label_dir)\n",
        "\n",
        "        # Hiển thị ảnh cùng với thông tin nhãn dự đoán\n",
        "        img = Image.open(img_path)\n",
        "        img_array = np.array(img.resize(display_size)) / 255.0  # Resize ảnh và chuẩn hóa giá trị pixel\n",
        "        axes[j // 2, j % 2].imshow(img_array)\n",
        "        axes[j // 2, j % 2].set_title(f\"Predicted Label: {predicted_class}\")\n",
        "\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}